---
title: "Generalized Linear Mixed Models for Prevalences"
author: "Coimbra, van der Kuil, van de Schoot"
date: "2025-07-20"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    toc_depth: 4
    number_sections: true
    code_folding: hide
  word_document:
    toc: true
    toc_depth: '4'
  pdf_document:
    toc: true
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE, cache = FALSE)

# Set the root directory for the entire document (recommended way)
knitr::opts_knit$set(root.dir = dirname(rstudioapi::getActiveDocumentContext()$path))

```

# Preparation

```{r load-packages}
library(readr)
library(metafor)
library(lme4)
library(influence.ME)
library(dplyr)
library(gt)
```

## Load Data

```{r load-data}
# load data
df_moderation <- read.csv2("../pre-processing/output/data_for_moderation_analyses.csv", dec = ".")

# Display the first rows to check the data
head(df_moderation)
```

## Descriptive Statistics

We provide basic descriptive statistics of the included studies, without excluding any data due to missingness.

```{r descriptives, message=FALSE}
summary_table <- data.frame(
  Description = c("Number of studies / cohorts", "Total sample size"),
  Value       = format(c(NROW(df_moderation),
                         sum(df_moderation$Sample_Size, na.rm = TRUE)),
                       big.mark = ","),
  check.names = FALSE
)

knitr::kable(summary_table, caption = "Descriptive Statistics of the Dataset")
```

### Descriptives Tables for All Studies

```{r descriptives-studies-table}
overview <- data.frame(
  `Authors (Study)`              = df_moderation$Study,
  `Sample Size`                  = df_moderation$Sample_Size,
  `Mean Age`                     = df_moderation$Mean_age,
  `Percentage Women`             = df_moderation$Percentage_women,
  `Assessed Trauma Type`         = df_moderation$Assessed_trauma_type,
  `Military`                     = df_moderation$Military,
  `Number of TP assessments`     = df_moderation$TP_assessments,
  `Number of Trajectories Found` = df_moderation$N_trajectories,
  check.names = FALSE
)

gt(overview) |>
  tab_header(title = "Study Overview") |>
  fmt_number(columns = "Sample Size", decimals = 0, use_seps = TRUE) |>
  fmt_number(columns = "Mean Age", decimals = 1) |>
  # If your percentages are 0â€“1, set scale_values = TRUE instead.
  fmt_percent(columns = "Percentage Women", decimals = 1, scale_values = FALSE) |>
  opt_row_striping() |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = "Authors (Study)")
  ) |>
  sub_missing(columns = everything(), missing_text = "â€”")
```

# Prevalences

```{r portable-glmm-function}
# Helper: portable function for pooled prevalence via GLMM with continuity correction
fit_glmm_prev <- function(df, event_col, n_col = "Sample_Size", label = event_col) {
  xi <- suppressWarnings(as.numeric(df[[event_col]]))
  ni <- suppressWarnings(as.numeric(df[[n_col]]))

  extreme <- !is.na(xi) & !is.na(ni) & (xi == 0 | xi == ni)
  xi[extreme] <- xi[extreme] + 0.5
  ni[extreme] <- ni[extreme] + 1

  fit <- metafor::rma.glmm(measure = "PLO", xi = xi, ni = ni, data = df)
  pr  <- predict(fit, transf = metafor::transf.ilogit)

  data.frame(
    Trajectory        = label,
    Pooled_Prevalence = as.numeric(pr$pred),
    CI_Lower          = as.numeric(pr$ci.lb),
    CI_Upper          = as.numeric(pr$ci.ub),
    Studies_included  = fit$k,
    logit             = unname(coef(fit)[1]),
    tau2              = as.numeric(fit$tau2),
    check.names = FALSE
  )
}
```

## ðŸš€ Low Symptom Trajectory

### Descriptives

We provide additional descriptives based on the Low trajectory variable, using the full dataset.

```{r Low-descriptives}

# Copy the dataset to avoid overwriting the original
df_low <- df_moderation

# Calculate Low_n as (percentage / 100) * sample size
df_low$Low_n <- round((df_low$Low_percentage / 100) * df_low$Sample_Size)

# Total number of individuals classified as Low (ignoring missingness in other variables)
total_Low_n <- sum(df_low$Low_n, na.rm = TRUE)

# Number of unique studies (assumes a column Study exists)
unique_Low_studies <- length(unique(df_low$Study[!is.na(df_low$Low_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Low trajectory", "Number of unique studies"),
  Value = format(c(total_Low_n, unique_Low_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Low Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **Low trajectory** using a Generalized Linear Mixed Model (GLMM).\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.


```{r Low-glmm}
Low_summary <- fit_glmm_prev(df_low, event_col = "Low_n", n_col = "Sample_Size",
                             label = "Low Symptoms Trajectory")

knitr::kable(Low_summary, caption = "Pooled Prevalence Estimate for Low Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding studies with Low trajectory â‰¥90%

```{r Low-sensitivity_1}
sens1_df <- subset(df_low,
                   !is.na(Low_n) & !is.na(Sample_Size) &
                   !is.na(Low_percentage) & Low_percentage < 90)
sens1 <- fit_glmm_prev(sens1_df, "Low_n", "Sample_Size", "Sensitivity 1: Exclude â‰¥90% Low")
knitr::kable(sens1, caption = "Sensitivity Analysis 1: Low Trajectory (Excl. â‰¥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r Low-sensitivity-2}
sens2_df <- subset(df_low,
                   !is.na(Low_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)
sens2 <- fit_glmm_prev(sens2_df, "Low_n", "Sample_Size", "Sensitivity 2: N > 999")
knitr::kable(sens2, caption = "Sensitivity Analysis 2: Low Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r Low-influential}

# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Low <- glmer(cbind(round(Low_n), Sample_Size - round(Low_n)) ~ 1 + (1 | Study),
                     data = df_low,
                     family = binomial)

# Run influence analysis by Study
infl <- influence(model_glmer_Low, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)


# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies <- unique(df_low$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r Low-sens-influential}
df_excl <- if (nrow(influential_table)) df_low[ !(df_low$Study %in% influential_table$Study_ID), ] else df_low
sens_infl <- fit_glmm_prev(df_excl, "Low_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")
knitr::kable(sens_infl, caption = "Sensitivity Analysis 3: Low Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:

```{r Low-glmer-summary}
# Intercept estimate & SE (logit scale)
sm <- coef(summary(model_glmer_Low))["(Intercept)", ]

# 95% CI on logit scale (fast Wald CI, avoids slow profiling)
ci <- suppressMessages(confint(model_glmer_Low, parm = "(Intercept)", method = "Wald"))

# Count of studies used in the model
k_study <- nlevels(lme4::getME(model_glmer_Low, "flist")$Study)

# Tidy summary on proportion scale
glmer_summary_Low <- data.frame(
  Model             = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(sm["Estimate"]), 3),
  CI_Lower          = round(plogis(ci[1]), 3),
  CI_Upper          = round(plogis(ci[2]), 3),
  Studies_included  = k_study,
  check.names = FALSE
)

knitr::kable(glmer_summary_Low, caption = "Low Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:

rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

## ðŸŒ¿ Decreasing Symptom Trajectory

### Descriptives

We provide additional descriptives based on the Decreasing trajectory variable, using the full dataset.

```{r Decreasing-descriptives}

# Copy the dataset to avoid overwriting the original
df_Decreasing <- df_moderation

# Calculate Decreasing_n as (percentage / 100) * sample size
df_Decreasing$Decreasing_n <- round((df_Decreasing$Decreasing_percentage / 100) * df_Decreasing$Sample_Size)

# Total number of individuals classified as Decreasing (ignoring missingness in other variables)
total_Decreasing_n <- sum(df_Decreasing$Decreasing_n, na.rm = TRUE)

# Number of unique studies (assumes a column Study exists)
unique_Decreasing_studies <- length(unique(df_Decreasing$Study[!is.na(df_Decreasing$Decreasing_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Decreasing trajectory", "Number of unique studies"),
  Value = format(c(total_Decreasing_n, unique_Decreasing_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Decreasing Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **Decreasing trajectory** using a Generalized Linear Mixed Model (GLMM).\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.


```{r Decreasing-glmm}
Decreasing_summary <- fit_glmm_prev(df_Decreasing, event_col = "Decreasing_n", n_col = "Sample_Size",
                             label = "Decreasing Symptoms Trajectory")

knitr::kable(Decreasing_summary, caption = "Pooled Prevalence Estimate for Decreasing Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding studies with Decreasing trajectory â‰¥90%

```{r Decreasing-sensitivity_1}
sens1_df <- subset(df_Decreasing,
                   !is.na(Decreasing_n) & !is.na(Sample_Size) &
                     !is.na(Decreasing_percentage) & Decreasing_percentage < 90)
sens1 <- fit_glmm_prev(sens1_df, "Decreasing_n", "Sample_Size", "Sensitivity 1: Exclude â‰¥90% Decreasing")
knitr::kable(sens1, caption = "Sensitivity Analysis 1: Decreasing Trajectory (Excl. â‰¥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r Decreasing-sensitivity-2}
sens2_df <- subset(df_Decreasing,
                   !is.na(Decreasing_n) & !is.na(Sample_Size) &
                     Sample_Size > 999)
sens2 <- fit_glmm_prev(sens2_df, "Decreasing_n", "Sample_Size", "Sensitivity 2: N > 999")
knitr::kable(sens2, caption = "Sensitivity Analysis 2: Decreasing Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r Decreasing-influential}

# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Decreasing <- glmer(cbind(round(Decreasing_n), Sample_Size - round(Decreasing_n)) ~ 1 + (1 | Study),
                     data = df_Decreasing,
                     family = binomial)

# Run influence analysis by Study
infl <- influence(model_glmer_Decreasing, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
           main = "Cook's Distance per Study",
           ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)


# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies <- unique(df_Decreasing$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r Decreasing-sens-influential}
df_excl <- if (nrow(influential_table)) df_Decreasing[ !(df_Decreasing$Study %in% influential_table$Study_ID), ] else df_Decreasing
sens_infl <- fit_glmm_prev(df_excl, "Decreasing_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")
knitr::kable(sens_infl, caption = "Sensitivity Analysis 3: Decreasing Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:
  
```{r Decreasing-glmer-summary}
# Intercept estimate & SE (logit scale)
sm <- coef(summary(model_glmer_Decreasing))["(Intercept)", ]

# 95% CI on logit scale (fast Wald CI, avoids sDecreasing profiling)
ci <- suppressMessages(confint(model_glmer_Decreasing, parm = "(Intercept)", method = "Wald"))

# Count of studies used in the model
k_study <- nlevels(lme4::getME(model_glmer_Decreasing, "flist")$Study)

# Tidy summary on proportion scale
glmer_summary_Decreasing <- data.frame(
  Model             = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(sm["Estimate"]), 3),
  CI_Decreasinger          = round(plogis(ci[1]), 3),
  CI_Upper          = round(plogis(ci[2]), 3),
  Studies_included  = k_study,
  check.names = FALSE
)

knitr::kable(glmer_summary_Decreasing, caption = "Decreasing Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:
  
  rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

## âš ï¸ Increasing Symptom Trajectory

### Descriptives

We provide additional descriptives based on the Increasing trajectory variable, using the full dataset.

```{r Increasing-descriptives}

# Copy the dataset to avoid overwriting the original
df_Increasing <- df_moderation

# Calculate Increasing_n as (percentage / 100) * sample size
df_Increasing$Increasing_n <- round((df_Increasing$Increasing_percentage / 100) * df_Increasing$Sample_Size)

# Total number of individuals classified as Increasing (ignoring missingness in other variables)
total_Increasing_n <- sum(df_Increasing$Increasing_n, na.rm = TRUE)

# Number of unique studies (assumes a column Study exists)
unique_Increasing_studies <- length(unique(df_Increasing$Study[!is.na(df_Increasing$Increasing_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Increasing trajectory", "Number of unique studies"),
  Value = format(c(total_Increasing_n, unique_Increasing_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Increasing Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **Increasing trajectory** using a Generalized Linear Mixed Model (GLMM).\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.


```{r Increasing-glmm}
Increasing_summary <- fit_glmm_prev(df_Increasing, event_col = "Increasing_n", n_col = "Sample_Size",
                             label = "Increasing Symptoms Trajectory")

knitr::kable(Increasing_summary, caption = "Pooled Prevalence Estimate for Increasing Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding studies with Increasing trajectory â‰¥90%

```{r Increasing-sensitivity_1}
sens1_df <- subset(df_Increasing,
                   !is.na(Increasing_n) & !is.na(Sample_Size) &
                     !is.na(Increasing_percentage) & Increasing_percentage < 90)
sens1 <- fit_glmm_prev(sens1_df, "Increasing_n", "Sample_Size", "Sensitivity 1: Exclude â‰¥90% Increasing")
knitr::kable(sens1, caption = "Sensitivity Analysis 1: Increasing Trajectory (Excl. â‰¥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r Increasing-sensitivity-2}
sens2_df <- subset(df_Increasing,
                   !is.na(Increasing_n) & !is.na(Sample_Size) &
                     Sample_Size > 999)
sens2 <- fit_glmm_prev(sens2_df, "Increasing_n", "Sample_Size", "Sensitivity 2: N > 999")
knitr::kable(sens2, caption = "Sensitivity Analysis 2: Increasing Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r Increasing-influential}

# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Increasing <- glmer(cbind(round(Increasing_n), Sample_Size - round(Increasing_n)) ~ 1 + (1 | Study),
                     data = df_Increasing,
                     family = binomial)

# Run influence analysis by Study
infl <- influence(model_glmer_Increasing, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
           main = "Cook's Distance per Study",
           ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)


# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies <- unique(df_Increasing$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r Increasing-sens-influential}
df_excl <- if (nrow(influential_table)) df_Increasing[ !(df_Increasing$Study %in% influential_table$Study_ID), ] else df_Increasing
sens_infl <- fit_glmm_prev(df_excl, "Increasing_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")
knitr::kable(sens_infl, caption = "Sensitivity Analysis 3: Increasing Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:
  
```{r Increasing-glmer-summary}
# Intercept estimate & SE (logit scale)
sm <- coef(summary(model_glmer_Increasing))["(Intercept)", ]

# 95% CI on logit scale (fast Wald CI, avoids sIncreasing profiling)
ci <- suppressMessages(confint(model_glmer_Increasing, parm = "(Intercept)", method = "Wald"))

# Count of studies used in the model
k_study <- nlevels(lme4::getME(model_glmer_Increasing, "flist")$Study)

# Tidy summary on proportion scale
glmer_summary_Increasing <- data.frame(
  Model             = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(sm["Estimate"]), 3),
  CI_Increasinger          = round(plogis(ci[1]), 3),
  CI_Upper          = round(plogis(ci[2]), 3),
  Studies_included  = k_study,
  check.names = FALSE
)

knitr::kable(glmer_summary_Increasing, caption = "Increasing Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:
  
  rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

## ðŸ©¸ High Symptom Trajectory

### Descriptives

We provide additional descriptives based on the High trajectory variable, using the full dataset.

```{r High-descriptives}

# Copy the dataset to avoid overwriting the original
df_High <- df_moderation

# Calculate High_n as (percentage / 100) * sample size
df_High$High_n <- round((df_High$High_percentage / 100) * df_High$Sample_Size)

# Total number of individuals classified as High (ignoring missingness in other variables)
total_High_n <- sum(df_High$High_n, na.rm = TRUE)

# Number of unique studies (assumes a column Study exists)
unique_High_studies <- length(unique(df_High$Study[!is.na(df_High$High_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in High trajectory", "Number of unique studies"),
  Value = format(c(total_High_n, unique_High_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for High Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **High trajectory** using a Generalized Linear Mixed Model (GLMM).\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.


```{r High-glmm}
High_summary <- fit_glmm_prev(df_High, event_col = "High_n", n_col = "Sample_Size",
                             label = "High Symptoms Trajectory")

knitr::kable(High_summary, caption = "Pooled Prevalence Estimate for High Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding studies with High trajectory â‰¥90%

```{r High-sensitivity_1}
sens1_df <- subset(df_High,
                   !is.na(High_n) & !is.na(Sample_Size) &
                     !is.na(High_percentage) & High_percentage < 90)
sens1 <- fit_glmm_prev(sens1_df, "High_n", "Sample_Size", "Sensitivity 1: Exclude â‰¥90% High")
knitr::kable(sens1, caption = "Sensitivity Analysis 1: High Trajectory (Excl. â‰¥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r High-sensitivity-2}
sens2_df <- subset(df_High,
                   !is.na(High_n) & !is.na(Sample_Size) &
                     Sample_Size > 999)
sens2 <- fit_glmm_prev(sens2_df, "High_n", "Sample_Size", "Sensitivity 2: N > 999")
knitr::kable(sens2, caption = "Sensitivity Analysis 2: High Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r High-influential}

# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_High <- glmer(cbind(round(High_n), Sample_Size - round(High_n)) ~ 1 + (1 | Study),
                     data = df_High,
                     family = binomial)

# Run influence analysis by Study
infl <- influence(model_glmer_High, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
           main = "Cook's Distance per Study",
           ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)


# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies <- unique(df_High$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r High-sens-influential}
df_excl <- if (nrow(influential_table)) df_High[ !(df_High$Study %in% influential_table$Study_ID), ] else df_High
sens_infl <- fit_glmm_prev(df_excl, "High_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")
knitr::kable(sens_infl, caption = "Sensitivity Analysis 3: High Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:
  
```{r High-glmer-summary}
# Intercept estimate & SE (logit scale)
sm <- coef(summary(model_glmer_High))["(Intercept)", ]

# 95% CI on logit scale (fast Wald CI, avoids sHigh profiling)
ci <- suppressMessages(confint(model_glmer_High, parm = "(Intercept)", method = "Wald"))

# Count of studies used in the model
k_study <- nlevels(lme4::getME(model_glmer_High, "flist")$Study)

# Tidy summary on proportion scale
glmer_summary_High <- data.frame(
  Model             = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(sm["Estimate"]), 3),
  CI_Higher          = round(plogis(ci[1]), 3),
  CI_Upper          = round(plogis(ci[2]), 3),
  Studies_included  = k_study,
  check.names = FALSE
)

knitr::kable(glmer_summary_High, caption = "High Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:
  
  rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

## ðŸŒ— Moderate Symptom Trajectory

### Descriptives

We provide additional descriptives based on the Moderate trajectory variable, using the full dataset.

```{r Moderate-descriptives}

# Copy the dataset to avoid overwriting the original
df_Moderate <- df_moderation

# Calculate Moderate_n as (percentage / 100) * sample size
df_Moderate$Moderate_n <- round((df_Moderate$Moderate_percentage / 100) * df_Moderate$Sample_Size)

# Total number of individuals classified as Moderate (ignoring missingness in other variables)
total_Moderate_n <- sum(df_Moderate$Moderate_n, na.rm = TRUE)

# Number of unique studies (assumes a column Study exists)
unique_Moderate_studies <- length(unique(df_Moderate$Study[!is.na(df_Moderate$Moderate_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Moderate trajectory", "Number of unique studies"),
  Value = format(c(total_Moderate_n, unique_Moderate_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Moderate Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **Moderate trajectory** using a Generalized Linear Mixed Model (GLMM).\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.


```{r Moderate-glmm}
Moderate_summary <- fit_glmm_prev(df_Moderate, event_col = "Moderate_n", n_col = "Sample_Size",
                             label = "Moderate Symptoms Trajectory")

knitr::kable(Moderate_summary, caption = "Pooled Prevalence Estimate for Moderate Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding studies with Moderate trajectory â‰¥90%

```{r Moderate-sensitivity_1}
sens1_df <- subset(df_Moderate,
                   !is.na(Moderate_n) & !is.na(Sample_Size) &
                     !is.na(Moderate_percentage) & Moderate_percentage < 90)
sens1 <- fit_glmm_prev(sens1_df, "Moderate_n", "Sample_Size", "Sensitivity 1: Exclude â‰¥90% Moderate")
knitr::kable(sens1, caption = "Sensitivity Analysis 1: Moderate Trajectory (Excl. â‰¥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r Moderate-sensitivity-2}
sens2_df <- subset(df_Moderate,
                   !is.na(Moderate_n) & !is.na(Sample_Size) &
                     Sample_Size > 999)
sens2 <- fit_glmm_prev(sens2_df, "Moderate_n", "Sample_Size", "Sensitivity 2: N > 999")
knitr::kable(sens2, caption = "Sensitivity Analysis 2: Moderate Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r Moderate-influential}

# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Moderate <- glmer(cbind(round(Moderate_n), Sample_Size - round(Moderate_n)) ~ 1 + (1 | Study),
                     data = df_Moderate,
                     family = binomial)

# Run influence analysis by Study
infl <- influence(model_glmer_Moderate, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
           main = "Cook's Distance per Study",
           ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)


# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies <- unique(df_Moderate$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r Moderate-sens-influential}
df_excl <- if (nrow(influential_table)) df_Moderate[ !(df_Moderate$Study %in% influential_table$Study_ID), ] else df_Moderate
sens_infl <- fit_glmm_prev(df_excl, "Moderate_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")
knitr::kable(sens_infl, caption = "Sensitivity Analysis 3: Moderate Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:
  
```{r Moderate-glmer-summary}
# Intercept estimate & SE (logit scale)
sm <- coef(summary(model_glmer_Moderate))["(Intercept)", ]

# 95% CI on logit scale (fast Wald CI, avoids sModerate profiling)
ci <- suppressMessages(confint(model_glmer_Moderate, parm = "(Intercept)", method = "Wald"))

# Count of studies used in the model
k_study <- nlevels(lme4::getME(model_glmer_Moderate, "flist")$Study)

# Tidy summary on proportion scale
glmer_summary_Moderate <- data.frame(
  Model             = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(sm["Estimate"]), 3),
  CI_Moderateer          = round(plogis(ci[1]), 3),
  CI_Upper          = round(plogis(ci[2]), 3),
  Studies_included  = k_study,
  check.names = FALSE
)

knitr::kable(glmer_summary_Moderate, caption = "Moderate Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:
  
  rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

# Tables for Paper

## Prevalences Summary Table (Table 1)

```{r prevalences-summary-table}
traj_order <- c("Low","Decreasing","Increasing","High","Moderate")

summaries <- list(
  Low        = Low_summary,
  Decreasing = Decreasing_summary,
  Increasing = Increasing_summary,
  High       = High_summary,
  Moderate   = Moderate_summary
)

# Totals per trajectory (N and % of all individuals)
trajectory_counts <- tibble(
  trajectory = factor(traj_order, levels = traj_order),
  N = c(
    total_Low_n,
    total_Decreasing_n,
    total_Increasing_n,
    total_High_n,
    total_Moderate_n
  )
) |>
  mutate(pct = round(100 * N / sum(N, na.rm = TRUE), 1))

# Build one tidy row per trajectory from its summary df
row_from_summary <- function(name, summ_df) {
  # take the first row of the summary (it has pooled stats)
  pr   <- summ_df$Pooled_Prevalence[1]
  lb   <- summ_df$CI_Lower[1]
  ub   <- summ_df$CI_Upper[1]
  k    <- summ_df$Studies_included[1]
  logit <- if ("logit" %in% names(summ_df)) summ_df$logit[1] else qlogis(pr)
  tau2  <- if ("tau2"  %in% names(summ_df)) summ_df$tau2[1]  else NA_real_

  # N (%) for this trajectory
  N_val  <- trajectory_counts$N[trajectory_counts$trajectory == name]
  P_val  <- trajectory_counts$pct[trajectory_counts$trajectory == name]

  tibble(
    trajectory = name,
    rel_prev   = sprintf("%.1f%%", pr * 100),
    ci_95      = sprintf("%.1f to %.1f%%", lb * 100, ub * 100),
    k          = as.integer(k),
    N_pct      = sprintf("%s (%.1f%%)", format(N_val, big.mark = ","), P_val),
    logit      = round(logit, 2),
    tau2       = round(tau2, 2)
  )
}

table1_df <- bind_rows(lapply(traj_order, function(nm) row_from_summary(nm, summaries[[nm]])))

# Render table
table1_df |>
  gt() |>
  cols_label(
    trajectory = "PTSD Symptom Trajectory",
    rel_prev   = "Relative Prevalence",
    ci_95      = "95%(CI)",
    k          = "k",
    N_pct      = "N (%)",
    logit      = "Logit Estimate",
    tau2       = html("&tau;<sup>2</sup>")
  ) |>
  tab_header(
    title    = md("**Table 1**"),
    subtitle = md("Relative Prevalence of PTSD Symptom Trajectories")
  ) |>
  cols_align("left",   columns = trajectory) |>
  cols_align("center", columns = c(rel_prev, ci_95, k, N_pct, logit, tau2)) |>
  fmt_integer(columns = k, use_seps = TRUE) |>
  fmt_number(columns = c(logit, tau2), decimals = 2) |>
  opt_row_striping() |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  ) |>
  tab_options(
    table.width = pct(100),
    data_row.padding = px(6),
    table.font.size = px(13)
  ) |>
  tab_source_note(
    source_note = html("<em>Note.</em> k represents the number of unique studies. Logit estimate reflects pooled prevalence on a log-odds scale. &tau;<sup>2</sup> indicates between-study heterogeneity; values &gt; 0.50 suggest substantial heterogeneity.")
  )
```